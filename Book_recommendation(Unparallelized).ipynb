{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('book_weights_sample.pkl', 'rb') as f:\n",
    "    book_weights_dic = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The book weights dictionary is organized as follows: the keys are book ids and the values are the weight for each topic. For the example below, book 3 has a weight of 0.63541293 on topic 14, 0.042711955 on topic 16, etc. Topics are numbered from 0 to 49 (50 topics in total, this number might change). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(14, 0.63541293), (16, 0.042711955), (30, 0.31054646)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_weights_dic[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the distance between each tweeter topic and each book topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS = 50\n",
    "handle = \"twitter_handle1\"\n",
    "with open('GoodReads/' + str(NUM_TOPICS) + '_Topics/' + handle + '_topic_dist_' + str(NUM_TOPICS) + '.pkl', 'rb') as f:\n",
    "    H1_topic_similarities = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here topic similarities contains the similarity between each tweet topic and each book topic. The key is the index for tweet topic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H1_topic_similarities.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From example, below topic similarity between the first tweet topic and all the book topics, the first cell is the similarity between tweet topic 0 and book topic 0, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63115036, 0.5410966 , 0.        , 0.60161729, 0.60287399,\n",
       "       0.37091192, 0.57781857, 0.        , 0.61218628, 0.53073806,\n",
       "       0.59359596, 0.75747244, 0.63990171, 0.64931094, 0.59167339,\n",
       "       0.72260887, 0.58345033, 0.57992813, 0.        , 0.65580549,\n",
       "       0.55813228, 0.59733332, 0.52914746, 0.67388694, 0.        ,\n",
       "       0.64509788, 0.63094447, 0.61634558, 0.6093578 , 0.61839498,\n",
       "       0.64139237, 0.39989721, 0.75945939, 0.50196681, 0.50925275,\n",
       "       0.67151635, 0.61885013, 0.56887963, 0.49521495, 0.67566146,\n",
       "       0.56198947, 0.57937586, 0.79542029, 0.61065288, 0.        ,\n",
       "       0.        , 0.56771489, 0.68436507, 0.62473132, 0.64290289])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H1_topic_similarities[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to calcuate the average similarity between each twitter topic and each book!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def book_recommend(topic_similarities, topk = 3):\n",
    "    TOP = topk # Reccomending the top 5 books\n",
    "\n",
    "    tweet_recommended = {}\n",
    "    for tweet_topic in topic_similarities.keys():\n",
    "        book_ave_similarity_dic = {}\n",
    "        for book_id in book_weights_dic.keys():\n",
    "            book_weights = book_weights_dic[book_id]\n",
    "            ave_similarity = 0\n",
    "            for book_topic, weight in book_weights:\n",
    "                ave_similarity += weight *  topic_similarities[tweet_topic][book_topic]\n",
    "            book_ave_similarity_dic[book_id] = ave_similarity\n",
    "        ## The code below is very ugly, it is essentiall sorte by value and take topk in Spark...\n",
    "        sorted_sim_dic = sorted(book_ave_similarity_dic.items(), key = lambda kv: kv[1], reverse = True) # This is essentially a sort by value in pyspark, probably where we can save the most time\n",
    "        top_books = sorted_sim_dic[:TOP]\n",
    "        tweet_recommended[tweet_topic] = top_books\n",
    "    return(tweet_recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_bookids = book_recommend(H1_topic_similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It returns a list of books it recommends top 3 books based on each topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can then check what each of the book is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(7967, 0.536600805949041),\n",
       "  (8648, 0.5365609490238615),\n",
       "  (9532, 0.5365146470126313)],\n",
       " 1: [(32542, 0.8258355597474107),\n",
       "  (24192, 0.8246464562975124),\n",
       "  (425029, 0.824095562715859)],\n",
       " 2: [(11127, 0.4682288891924464),\n",
       "  (65641, 0.46814034673338345),\n",
       "  (84119, 0.4680836963448835)],\n",
       " 3: [(4374400, 0.5490727661632726),\n",
       "  (8492825, 0.5490133911965749),\n",
       "  (6931356, 0.5488454908893073)],\n",
       " 4: [(64216, 0.653977687619366),\n",
       "  (386372, 0.6207194534347562),\n",
       "  (34497, 0.600169278863835)]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_bookids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
